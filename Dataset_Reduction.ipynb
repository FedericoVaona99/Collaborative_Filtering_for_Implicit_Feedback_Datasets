{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482d6076",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9e375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: Imports ===\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ce22b",
   "metadata": {},
   "source": [
    "# 2. Load user profiles and keep first 500 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c13f3ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiles shape (reduced): (500, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>signup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#id</td>\n",
       "      <td>gender</td>\n",
       "      <td>age</td>\n",
       "      <td>country</td>\n",
       "      <td>registered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Aug 13, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_000002</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "      <td>Feb 24, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_000003</td>\n",
       "      <td>m</td>\n",
       "      <td>22</td>\n",
       "      <td>United States</td>\n",
       "      <td>Oct 30, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_000004</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr 26, 2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  gender  age        country        signup\n",
       "0          #id  gender  age        country    registered\n",
       "1  user_000001       m  NaN          Japan  Aug 13, 2006\n",
       "2  user_000002       f  NaN           Peru  Feb 24, 2006\n",
       "3  user_000003       m   22  United States  Oct 30, 2005\n",
       "4  user_000004       f  NaN            NaN  Apr 26, 2006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Cell 2: Load user profiles and keep first 500 users ===\n",
    "# Paths\n",
    "profiles_path = \"Original-lastfm-dataset-1K/userid-profile.tsv\"\n",
    "\n",
    "# Load profiles (small file)\n",
    "profiles_df = pd.read_csv(\n",
    "    profiles_path,\n",
    "    sep=\"\\t\",\n",
    "    names=[\"user_id\", \"gender\", \"age\", \"country\", \"signup\"],\n",
    "    header=None,\n",
    "    dtype=str\n",
    ")\n",
    "\n",
    "# Keep only the first 500 users\n",
    "users_keep = profiles_df[\"user_id\"].head(500).tolist()\n",
    "profiles_df = profiles_df.head(500)                     \n",
    "\n",
    "print(\"Profiles shape (reduced):\", profiles_df.shape)\n",
    "display(profiles_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a23b4ab",
   "metadata": {},
   "source": [
    "# 3. Stream-reduce listening history while keeping 500 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e2d473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done] Wrote 2,057,492 rows to Datasets-lastfm-reduced\\listens_first500_CAP.csv\n"
     ]
    }
   ],
   "source": [
    "# === Cell 3: Stream-reduce listening history while keeping 500 users ===\n",
    "# Goal:\n",
    "# - Keep exactly your selected 500 users (users_keep)\n",
    "# - Shrink the listening history via CAP_PER_USER (primary knob)\n",
    "#\n",
    "# This streams the big TSV in chunks and writes out a reduced CSV\n",
    "# without loading all 19M rows into RAM.\n",
    "\n",
    "# Input/Output paths\n",
    "DATA_DIR = \"Original-lastfm-dataset-1K\"\n",
    "SRC = os.path.join(DATA_DIR, \"userid-timestamp-artid-artname-traid-traname.tsv\")\n",
    "\n",
    "OUT_DIR = \"Datasets-lastfm-reduced\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "OUT_LISTENS = os.path.join(OUT_DIR, \"listens_first500_CAP.csv\")  # reduced listens CSV\n",
    "\n",
    "# Schema & reader options\n",
    "COLS = [\"user_id\", \"timestamp\", \"artist_id\", \"artist_name\", \"track_id\", \"track_name\"]\n",
    "CHUNKSIZE = 500_000  # tune RAM \n",
    "\n",
    "# Reduction knobs \n",
    "CAP_PER_USER = 5000   \n",
    "\n",
    "users_keep_set = set(users_keep)\n",
    "\n",
    "# Prepare output with header\n",
    "with open(OUT_LISTENS, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    f.write(\",\".join(COLS) + \"\\n\")\n",
    "\n",
    "kept_counts = defaultdict(int)\n",
    "rows_written = 0\n",
    "\n",
    "reader = pd.read_csv(\n",
    "    SRC,\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    engine=\"python\",        \n",
    "    dtype=str,\n",
    "    na_filter=False,\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    on_bad_lines=\"skip\",    # skip malformed lines\n",
    "    encoding=\"utf-8\",\n",
    "    chunksize=CHUNKSIZE,\n",
    ")\n",
    "\n",
    "for chunk in reader:\n",
    "    # Normalize to exactly 6 columns (some rows may have extra tabs)\n",
    "    if chunk.shape[1] < 6:\n",
    "        continue\n",
    "    if chunk.shape[1] > 6:\n",
    "        chunk = chunk.iloc[:, :6]\n",
    "    chunk.columns = COLS\n",
    "\n",
    "    # Keep only the selected 500 users\n",
    "    sub = chunk[chunk[\"user_id\"].isin(users_keep_set)]\n",
    "    if sub.empty:\n",
    "        continue\n",
    "\n",
    "    # Enforce per-user cap across chunks\n",
    "    parts = []\n",
    "    for u, grp in sub.groupby(\"user_id\", sort=False):\n",
    "        remain = CAP_PER_USER - kept_counts[u]\n",
    "        if remain > 0:\n",
    "            take = grp.iloc[:remain]\n",
    "            if not take.empty:\n",
    "                parts.append(take)\n",
    "                kept_counts[u] += len(take)\n",
    "\n",
    "    if parts:\n",
    "        out = pd.concat(parts, ignore_index=True)\n",
    "        out.to_csv(OUT_LISTENS, mode=\"a\", index=False, header=False, encoding=\"utf-8\")\n",
    "        rows_written += len(out)\n",
    "\n",
    "print(f\"[Done] Wrote {rows_written:,} rows to {OUT_LISTENS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c197a2",
   "metadata": {},
   "source": [
    "# 4. Save reduced profiles (aligned with the 500 users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cef215d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reduced datasets:\n",
      "Profiles -> Datasets-lastfm-reduced\\profiles_first500.csv\n",
      "Listens  -> Datasets-lastfm-reduced\\listens_first500_CAP.csv\n"
     ]
    }
   ],
   "source": [
    "# === Cell 4: Save reduced profiles (aligned with the 500 users) ===\n",
    "OUT_PROFILES = os.path.join(OUT_DIR, \"profiles_first500.csv\") \n",
    "profiles_df.to_csv(OUT_PROFILES, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved reduced datasets:\")\n",
    "print(\"Profiles ->\", OUT_PROFILES)\n",
    "print(\"Listens  ->\", OUT_LISTENS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b136f8e0",
   "metadata": {},
   "source": [
    "# 5. Load reduced listens into a DataFrame for immediate use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18790388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced listens_df shape: (2057492, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04T23:08:57Z</td>\n",
       "      <td>f1b1cf71-bd35-4e99-8624-24a6e15f133a</td>\n",
       "      <td>Deep Dish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuck Me Im Famous (Pacha Ibiza)-09-28-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04T13:54:10Z</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Composition 0919 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04T13:52:04Z</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mc2 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04T13:42:52Z</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hibari (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04T13:42:11Z</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mc1 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id             timestamp                             artist_id  \\\n",
       "0  user_000001  2009-05-04T23:08:57Z  f1b1cf71-bd35-4e99-8624-24a6e15f133a   \n",
       "1  user_000001  2009-05-04T13:54:10Z  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "2  user_000001  2009-05-04T13:52:04Z  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "3  user_000001  2009-05-04T13:42:52Z  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "4  user_000001  2009-05-04T13:42:11Z  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "\n",
       "  artist_name track_id                                  track_name  \n",
       "0   Deep Dish      NaN  Fuck Me Im Famous (Pacha Ibiza)-09-28-2007  \n",
       "1        坂本龍一      NaN           Composition 0919 (Live_2009_4_15)  \n",
       "2        坂本龍一      NaN                        Mc2 (Live_2009_4_15)  \n",
       "3        坂本龍一      NaN                     Hibari (Live_2009_4_15)  \n",
       "4        坂本龍一      NaN                        Mc1 (Live_2009_4_15)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Cell 5: Load reduced listens into a DataFrame for immediate use ===\n",
    "\n",
    "listens_df = pd.read_csv(OUT_LISTENS)\n",
    "print(\"Reduced listens_df shape:\", listens_df.shape)\n",
    "display(listens_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
